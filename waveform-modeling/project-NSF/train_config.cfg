train                = true

# random seed 
random_seed          = 1811626773

# train it for 50 epochs
max_epochs_no_best   = 50
max_epochs           = 50

# network file name (default)
network              = ./network.jsn

# trained after every every epoch will be saved
autosave 	     = true
validate_every       = 1

# default configurations (no need to change)
#  layer-size-dependent uniform distribution for weight initialization
weights_dist         = uninorm
weights_normal_sigma = 0.1
weights_normal_mean  = 0
#  turn off input random noise
input_noise_sigma    = 0
#  no need to shuffle utterances in order
shuffle_fractions    = false
shuffle_sequences    = false

stochastic           = true

# memory space is limited, don't use parallel_sequences > 1
parallel_sequences   = 1
# maximum length for utterance truncation
#  one long utterance will be divided into small pieces shorter than truncate_seq*1.5
#  if memory space is insuffcient, reduce the this number
truncate_seq         = 15000

# Optimization option
# =0: normal SGD
# =1: ADGRAD
# =3: SGD + ADAGRAD
#     Please use OptimizerSecondLR to specify the learning rate for ADAGRAD
# =4: SGD + learning_rate decay
# =5: Adam
Optimizer            = 5
learning_rate        = 0.0003
momentum	     = 0

# These options will be specified in 01_train_network.sh as commandline arguments
# But these options can also be configured here using the following format:

# The data.nc files. These data.nc files contains the target waveform and input
# time index files
#train_file           = /gs/hs0/tgh-18IAU/wang/DATA/CMU/slt/DATA_float/DATA_TRAIN/data.nc1
#val_file             = /gs/hs0/tgh-18IAU/wang/DATA/CMU/slt/DATA_float/DATA_VAL/data.nc1

# These options specify the path and configs for the acoustic features
#ExtInputDirs        = /gs/hs0/tgh-18IAU/wang/DATA/CMU/slt/mfbsp_trn,/gs/hs0/tgh-18IAU/wang/DATA/CMU/slt/f0_trn
#ExtInputExts        = .mfbsp,.f0
#ExtInputDims        = 80_1
#source_data_ms      = /gs/hs0/tgh-18IAU/wang/DATA/CMU/slt/mfbsp_f0.meanstd.bin
#resolutions         = 80
